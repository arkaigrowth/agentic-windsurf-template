# **NOTE: This was the repo-setup prompt (generated by Gemini 2.5 Pro, May ’25 edition) that was used to build this entire repo.**

# You can disregard this page and simply use the rest of the repo as-is. The prompt below is for educational purposes only.

8==============================================================================================================D~~~~

**SYSTEM PROMPT (For you to give to Windsurf/Claude 3.7 Sonnet):**

#BEGINPROMPT
"You are an expert AI Engineering Assistant. Your task is to help me, a Senior AI/ML DevOps Engineer, set up a best-practice directory structure and initial template files for a new project: `[PROJECT_NAME_PLACEHOLDER]`. This setup will heavily leverage Agentic Coding principles and integrate with my available Model Context Protocol (MCP) servers. We are adapting the 3-folder system (ai_docs, specs, and a tool-specific prompt directory) for use within the Windsurf environment.

**My Available MCP Servers (from my mcp.json):**

* `context7`: Context-aware OSS docs & code snippets.
* `tavily`: Real-time web search & extraction.
* `fetch`: Fetch any URL -> clean Markdown/JSON.
* `browser`: Headless Chrome automation / screenshots.
* `postgres`: Postgres inspector & SQL execution.
* `git`: Git repo search / diff / PR helper.
* `memory`: Long-term semantic memory store.
* `figma`: Access Figma design data.
* `cloudflare`: Cloudflare developer docs lookup & Workers/DNS analytics.

**Our Core Philosophy:**

1. **Context is King:** The AI (you) must have all necessary information, leveraging MCP servers where appropriate.
2. **The Plan is the Prompt:** Detailed, human-refined plans are crucial for effective AI collaboration.
3. **Agentic Coding:** You will help with planning, drafting, and eventually implementing based on these plans, using MCP tools to gather information and perform actions.
4. **Reusable Prompts:** We will create templates for common interactions, incorporating MCP server usage.

**Instructions:**
Please generate the content for the following files. For each file, provide the full file path and then the content in a markdown code block.

**I. Directory Structure (For my reference):**

[PROJECT_NAME_PLACEHOLDER]/
├── .windsurf_prompts/
│   ├── README.md
│   └── commands/
│       ├── README.md
│       ├── prime_project_context_with_mcp.md  # Enhanced priming
│       └── draft_feature_spec_with_mcp.md     # Enhanced drafting
├── ai_docs/
│   ├── README.md
│   ├── example_external_api.md
│   └── project_architecture_v1.md
├── specs/
│   ├── README.md
│   └── template_feature_specification.md
└── README.md

---

**II. Generate File Contents:**

**1. Main Project README (`[PROJECT_NAME_PLACEHOLDER]/README.md`):**

* (Content similar to previous prompt, but ensure the "Recommended Windsurf Workflow" section reflects MCP usage in priming and plan drafting, e.g., "AI uses `git` MCP to list files, `fetch` MCP to get external docs, `tavily` for research during planning.")

**2. Windsurf Prompts README (`[PROJECT_NAME_PLACEHOLDER]/.windsurf_prompts/README.md`):**

* (Content similar to previous prompt.)

**3. Windsurf Commands README (`[PROJECT_NAME_PLACEHOLDER]/.windsurf_prompts/commands/README.md`):**

* (Content similar to previous prompt, but add a note: "Many of these prompt templates will suggest the use of specific MCP servers (e.g., `git`, `tavily`, `fetch`). Ensure Windsurf is configured to access these servers for optimal results.")

**4. Enhanced Context Priming Prompt Template (`[PROJECT_NAME_PLACEHOLDER]/.windsurf_prompts/commands/prime_project_context_with_mcp.md`):**

* Purpose: A template to give Windsurf initial project context, leveraging MCP servers.
* Content:

  ```markdown
  ## PROJECT CONTEXT PRIMING (with MCP) ##

    **Objective:** To provide you, my AI assistant, with comprehensive context about the `[PROJECT_NAME_PLACEHOLDER]` project using available MCP servers.

    **Instructions for AI:**
     1.  Acknowledge you've received this priming prompt.
     2.  **Use the `git` MCP server:** Execute `git.get_current_branch` and `git.log --oneline -n 5` to understand the current branch and recent commit history. Summarize this.
     3.  **Use the `git` MCP server:** Execute `git.ls_files` to get a list of all tracked files.
     4.  I will provide the content of the main project `README.md`. Please read it.
         (User: Paste `[PROJECT_NAME_PLACEHOLDER]/README.md` content here)
     5.  Based on the README, git information, and file list, please provide a concise overview of the project's current state, purpose, and architecture as you understand it.
     6.  **Use the `memory` MCP server:** Write a summary of this project overview to your long-term memory with a key like `project_overview_[PROJECT_NAME_PLACEHOLDER]`.
     7.  Confirm you are ready for further tasks.

    **Key files/directories to pay special attention to (if known by user already):**
     *   `ai_docs/`: Contains API specifications, architectural documents.
     *   `specs/`: Contains detailed feature plans.
     *   `src/`: (Assuming a common source directory)
  ```
* **Explanation of MCP choices:**

  * `git` MCP: Directly gets branch, recent commits, and file list, which is more reliable and efficient than me pasting it. This is a direct replacement for the manual step.
  * `memory` MCP: Stores the AI's understanding for future sessions, making context priming more efficient over time.

**5. Enhanced Feature Spec Drafting Prompt Template (`[PROJECT_NAME_PLACEHOLDER]/.windsurf_prompts/commands/draft_feature_spec_with_mcp.md`):**

* Purpose: A template to ask Windsurf to help draft a feature spec, using MCPs for research.
* Content:

  ```markdown
  ## DRAFT FEATURE SPECIFICATION (with MCP) ##

    **Objective:** Please help me draft a detailed feature specification for the following request. We will use the standard template located at `specs/template_feature_specification.md`. Leverage MCP servers for research and information gathering.

    **My Feature Request:**
     `[USER: PASTE YOUR HIGH-LEVEL FEATURE REQUEST HERE. Be as clear as possible. If it involves external services or specific technologies, mention them so the AI can use MCPs for research.]`
     *(Example: "Draft a plan to integrate the Stripe API for payment processing, specifically for one-time charges.")*

    **Instructions for AI:**
     1.  Acknowledge the feature request.
     2.  **Research (if applicable, based on request):**
         *   If the request involves external APIs or technologies, **use the `tavily` MCP server** to search for relevant official documentation, best practices, and common integration patterns. For example: `tavily.search "Stripe API one-time charge documentation"`
         *   If specific URLs are provided or found, **use the `fetch` MCP server** to get the content of those pages. For example: `fetch https://stripe.com/docs/api/charges/create`
         *   If the request involves UI/UX based on existing designs, and a Figma link is available, I (the user) can provide it, and you can suggest how the `figma` MCP server might be used to extract details (though I will perform the `figma` MCP calls if needed).
         *   If the request involves database interactions, you can formulate questions for me to ask the `postgres` MCP server (e.g., "Ask `postgres.get_schema 'public'` to understand existing table structures").
     3.  I will now provide the content of `specs/template_feature_specification.md`.
         (User: Paste content of `specs/template_feature_specification.md` here)
     4.  Based on my feature request, your research using MCP servers, and the provided template, please generate a DRAFT specification.
     5.  For each section of the template, provide detailed and actionable content, incorporating insights from your MCP-assisted research.
     6.  The output should be the full content for a new file: `specs/feature_draft_[brief_feature_name].md`. I will then copy this into the actual file.
  ```
* **Explanation of MCP choices:**

  * `tavily` & `fetch`: For researching external APIs, libraries, or concepts mentioned in the feature request. This makes the AI's plan more informed.
  * `figma` (suggested use): If UI is involved, the AI can guide the user on what Figma data might be relevant.
  * `postgres` (suggested use): If DB changes are needed, the AI can ask for schema info to make better suggestions.

**6. AI Docs README (`[PROJECT_NAME_PLACEHOLDER]/ai_docs/README.md`):**

* (Content similar to previous prompt, but add: "Information gathered via MCP servers (e.g., `fetch` for API docs) can be summarized and stored here for persistent project knowledge.")

**7. Example External API Doc (`[PROJECT_NAME_PLACEHOLDER]/ai_docs/example_external_api.md`):**

* (Content similar to previous prompt. Add a note: "This document can be initially populated using the `fetch` MCP server on the API's official documentation URL, then refined by a human.")

**8. Project Architecture Doc (`[PROJECT_NAME_PLACEHOLDER]/ai_docs/project_architecture_v1.md`):**

* (Content similar to previous prompt. Add a note: "Consider using the `memory` MCP server to store key architectural decisions or summaries for easy recall by the AI in future sessions.")

**9. Specs README (`[PROJECT_NAME_PLACEHOLDER]/specs/README.md`):**

* (Content similar to previous prompt, but add: "AI assistants, using tools like the `tavily` and `fetch` MCP servers, can help research and draft these initial specifications.")

**10. Template Feature Specification (`[PROJECT_NAME_PLACEHOLDER]/specs/template_feature_specification.md`):**
    *   (Content similar to previous prompt. In section 5.1 Data Model Changes, you could add a note: "*(AI: If relevant, ask user to query DB schema using `postgres` MCP for existing structures.)*". In section 5.2 API Endpoint Changes, add: "*(AI: If integrating external API, refer to information fetched via `tavily` or `fetch` MCPs.)*")

---

Please generate the content for these 10 files. I will then create the directory structure and save these files accordingly. This will form the foundation of my Agentic Coding workflow in Windsurf, leveraging my MCP servers.
"

How This Enhanced Prompt Leverages Your MCP Servers:

prime_project_context_with_mcp.md:

git MCP: Automates fetching the file list and recent commit history, providing more accurate and up-to-date context than manual pasting.

memory MCP: Instructs the AI to store its summarized understanding of the project. In subsequent sessions, you could add a step to recall this summary using memory.read "project_overview_[PROJECT_NAME_PLACEHOLDER]", potentially reducing the need to re-provide the full README every time.

draft_feature_spec_with_mcp.md:

tavily & fetch MCPs: Empowers the AI to perform initial research for the feature plan. If the feature involves a new library or API, the AI can look up its documentation and incorporate that into the draft plan. This makes the AI a more active participant in the planning phase.

figma & postgres MCPs (Guidance): While the AI can't directly use them without your intervention in Windsurf (as it doesn't have direct execution control for all MCPs in all environments), it can guide you on what information to retrieve using these tools. For example, "To better design the UI, please use the figma MCP to get details for component X. Or, "To understand database impact, please run postgres.get_table_definition 'users_table' and provide the output."

Important Considerations for Your Windsurf + MCP Setup:

Windsurf MCP Integration: The effectiveness of these MCP calls depends on how Windsurf is configured to interact with your MCP server setup. You'll need to ensure Windsurf can "see" and trigger these MCPs. If Windsurf doesn't directly trigger them based on the text (e.g., git.ls_files), the prompt instructs the AI to ask you to run the command and provide the output. This is a manual bridge but still leverages the MCP's capability.

API Keys & Environment Variables: For MCPs like tavily, postgres, cloudflare, ensure the necessary API keys and connection strings are correctly set up in the environment where your MCP servers (and potentially Windsurf, if it directly invokes them) are running. The prompt assumes these are handled outside of the prompt itself, as per your mcp.json.

Iterative Refinement: This is a starting point. As you use this system, you'll refine these prompt templates. For example, you might create more specialized priming prompts or feature drafting prompts for different types of tasks.

Cost of MCP Calls: Be mindful that some MCP calls (especially to powerful models or search APIs) might have associated costs.

This enhanced prompt should give you a much more powerful and automated starting point for your Agentic Coding setup in Windsurf, making good use of your existing MCP infrastructure! Let me know your thoughts!
